{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('./utils')\n",
    "from utils import *\n",
    "from rank import *\n",
    "from process import * \n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "# データ保存先\n",
    "data_folda = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* masterからデータを追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### master data から加えるデータを定義\n",
    "add_list=['name',\"prefecture_name\",'head_branch','opened_on', 'created_at','genre_first_name', \n",
    "          'genre_second_name','genre_third_name','northlatitude', 'eastlongitude',\n",
    "          'net_reservation_flg','price_range_lunch_owner','price_range_dinner_owner', \n",
    "          'price_range_lunch_user','price_range_dinner_user',\n",
    "          # 20240312追加\n",
    "          'all_photo_count','photo_food_count','photo_drink_count',\n",
    "          'photo_interior_count','photo_exterior_count','official_info_flg','max_visit_month']\n",
    "\n",
    "# make_timeseries_data.ipynb で作成したデータを読み込む\n",
    "pseudo_time_series=pd.read_pickle(data_folda+'skeleton_train.pkl')\n",
    "\n",
    "# 直近三カ月の閉店率を計算して保存\n",
    "# pseudo_time_series=pseudo_time_series[pseudo_time_series['base_date']>='2022-08-31']\n",
    "# close_ratios=calculate_close_ratio(pseudo_time_series, data_folda)\n",
    "# close_ratios=pd.read_pickle(data_folda+'close_ratios.pkl')\n",
    "\n",
    "# 三カ月の閉店率を読み込み\n",
    "close_ratios=pd.read_pickle(data_folda+'close_ratios.pkl')\n",
    "\n",
    "# 2023-01-01からの閉店を予測する。base_date が 2023-01-01の一日前以後が対象\n",
    "pseudo_time_series=pseudo_time_series[pseudo_time_series['base_date']>='2022-12-31']\n",
    "# base_date が 2023年1月1日以降のデータを抽出 (closed_date がそれ以降の閉店店舗しかクロールしていないため)\n",
    "pseudo_time_series = add_master_data(pseudo_time_series, data_folda, add_list, \"restaurant_data.csv\")\n",
    "pseudo_time_series=pd.merge(pseudo_time_series,close_ratios,on=[\"base_date\",\"genre_first_name\"],how=\"left\")\n",
    "pseudo_time_series.to_pickle(data_folda+'train_with_master.pkl')\n",
    "\n",
    "pseudo_time_series_test3=pd.read_pickle(data_folda+'skeleton_test_3month.pkl')\n",
    "pseudo_time_series_test3 = add_master_data(pseudo_time_series_test3, data_folda, add_list, \"restaurant_data.csv\")\n",
    "pseudo_time_series_test3=pd.merge(pseudo_time_series_test3,close_ratios,on=[\"base_date\",\"genre_first_name\"],how=\"left\")\n",
    "pseudo_time_series_test3.to_pickle(data_folda+'skeleton_test_3month_master.pkl')\n",
    "\n",
    "pseudo_time_series_test6=pd.read_pickle(data_folda+'skeleton_test_6month.pkl')\n",
    "pseudo_time_series_test6 = add_master_data(pseudo_time_series_test6, data_folda, add_list, \"restaurant_data.csv\")\n",
    "pseudo_time_series_test3=pd.merge(pseudo_time_series_test6,close_ratios,on=[\"base_date\",\"genre_first_name\"],how=\"left\")\n",
    "pseudo_time_series_test6.to_pickle(data_folda+'skeleton_test_6month_master.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['restaurant_id', 'original_id', 'closed_date', 'base_date',\n",
       "       'target3', 'target6', 'eval_period', 'id', 'name',\n",
       "       'prefecture_name', 'head_branch', 'opened_on', 'created_at',\n",
       "       'genre_first_name', 'genre_second_name', 'genre_third_name',\n",
       "       'northlatitude', 'eastlongitude', 'net_reservation_flg',\n",
       "       'price_range_lunch_owner', 'price_range_dinner_owner',\n",
       "       'price_range_lunch_user', 'price_range_dinner_user',\n",
       "       'all_photo_count', 'photo_food_count', 'photo_drink_count',\n",
       "       'photo_interior_count', 'photo_exterior_count',\n",
       "       'official_info_flg', 'real_opened_date', 'openning_days',\n",
       "       'days_from_lastvisit', 'close_ratio_genre'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_time_series.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* V_GOOGLE からデータを追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_series = pd.read_pickle(data_folda+'skeleton_train.pkl')\n",
    "pseudo_time_series=pseudo_time_series[pseudo_time_series['base_date']>='2022-12-31']\n",
    "add_list=[\"restaurant_id\",\"overview.aggregateRating\",\"overview.reviewCount\",\"general_rank\"]\n",
    "pseudo_time_series = add_v_google(pseudo_time_series, data_folda, add_list)\n",
    "pseudo_time_series.to_pickle(data_folda+'skeleton_train_with_google.pkl')\n",
    "\n",
    "pseudo_time_series_test = pd.read_pickle(data_folda+'skeleton_test_3month.pkl')\n",
    "add_list=[\"restaurant_id\",\"overview.aggregateRating\",\"overview.reviewCount\",\"general_rank\"]\n",
    "pseudo_time_series_test = add_v_google(pseudo_time_series_test, data_folda, add_list)\n",
    "pseudo_time_series_test.to_pickle(data_folda+'skeleton_test_3month_google.pkl')\n",
    "\n",
    "pseudo_time_series_test = pd.read_pickle(data_folda+'skeleton_test_6month.pkl')\n",
    "add_list=[\"restaurant_id\",\"overview.aggregateRating\",\"overview.reviewCount\",\"general_rank\"]\n",
    "pseudo_time_series_test = add_v_google(pseudo_time_series_test, data_folda, add_list)\n",
    "pseudo_time_series_test.to_pickle(data_folda+'skeleton_test_6month_google.pkl')\n",
    "\n",
    "del pseudo_time_series, pseudo_time_series_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* V_RETTY からデータを追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#追加する変数をリストで定義\n",
    "add_list=[\"restaurant_id\",'infos.isOfficial', \n",
    "       'infos.familiar.users.count', 'infos.familiar.stars',\n",
    "       'infos.onlineReservation_RETTY', 'infos.access.transferTime1','infos.access.transferTime2','infos.access.transferTime3',\n",
    "       'infos.numberOfSeats.value', 'infos.counterSeats.value',\n",
    "       'infos.privateRoom.value', 'infos.updateInfo.firstReviewDate',\n",
    "       'infos.wantToGo', 'infos.updateInfo.lastReviewDate',\n",
    "       'infos.went', 'infos.rateByWent', 'infos.excellent', 'infos.coupon',\n",
    "       'infos.photoCount.Photograph', 'infos.photoCount.Cooking',\n",
    "       'infos.photoCount.Interior', 'infos.photoCount.Exterior',\n",
    "       'infos.photoCount.Menu', 'infos.reviewCount.Review',\n",
    "       'infos.reviewCount.Lunch', 'infos.reviewCount.Dinner',\n",
    "       'menus.course_list_count',\n",
    "       'menus.dishes_list_count', 'menus.lunch_list_count',\n",
    "       'menus.drink_list_count', 'menus.takeout_list_count',\n",
    "       'infos.familiar.users.genge','infos.reserveEntireStore',\"general_rank_RETTY\"]\n",
    " \n",
    "pseudo_time_series = pd.read_pickle(data_folda+'skeleton_train.pkl')         \n",
    "pseudo_time_series=pseudo_time_series[pseudo_time_series['base_date']>='2022-12-31']\n",
    "pseudo_time_series = add_v_retty(pseudo_time_series, data_folda, add_list, master_name=\"V_RETTY\",read_from_snowflake=False)\n",
    "pseudo_time_series.to_pickle(data_folda+'train_with_retty.pkl')\n",
    "\n",
    "pseudo_time_series_test = pd.read_pickle(data_folda+'skeleton_test_3month.pkl')\n",
    "pseudo_time_series_test = add_v_retty(pseudo_time_series_test, data_folda, add_list, master_name=\"V_RETTY\",read_from_snowflake=False)\n",
    "pseudo_time_series_test.to_pickle(data_folda+'skeleton_test_3month_retty.pkl')\n",
    "\n",
    "pseudo_time_series_test = pd.read_pickle(data_folda+'skeleton_test_6month.pkl')\n",
    "pseudo_time_series_test = add_v_retty(pseudo_time_series_test, data_folda, add_list, master_name=\"V_RETTY\",read_from_snowflake=False)\n",
    "pseudo_time_series_test.to_pickle(data_folda+'skeleton_test_6month_retty.pkl')\n",
    "\n",
    "del pseudo_time_series, pseudo_time_series_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* HOTPEPPER からデータを追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_list=['restaurant_id','infos.aggregateRating','infos.ratingReview',\n",
    "          'infos.satisfaction.percentage1','infos.satisfaction.percentage2','infos.satisfaction.percentage3',\n",
    "          'infos.couponCount','infos.onlineReservation_HOTPEPPER','infos.ownerRegistration','infos.ticket',\n",
    "          'photos.allCount','photos.appearanceCount','photos.drinkCount','photos.foodCount','photos.otherCount',\n",
    "          'photos.postCount','menus.courseListCount']\n",
    "\n",
    "\n",
    "pseudo_time_series = pd.read_pickle(data_folda+'skeleton_train.pkl')\n",
    "pseudo_time_series=pseudo_time_series[pseudo_time_series['base_date']>='2022-12-31']\n",
    "pseudo_time_series= reduce_mem_usage(pseudo_time_series)\n",
    "pseudo_time_series = add_v_hotpepper(pseudo_time_series, data_folda, add_list, master_name=\"V_HOTPEPPER\",read_from_snowflake=False)\n",
    "pseudo_time_series.to_pickle(data_folda+'train_with_hotpepper.pkl')\n",
    "\n",
    "pseudo_time_series_test3 = pd.read_pickle(data_folda+'skeleton_test_3month.pkl')\n",
    "pseudo_time_series_test3= reduce_mem_usage(pseudo_time_series_test3)\n",
    "pseudo_time_series_test3 = add_v_hotpepper(pseudo_time_series_test3, data_folda, add_list, master_name=\"V_HOTPEPPER\",read_from_snowflake=False) \n",
    "pseudo_time_series_test3.to_pickle(data_folda+'skeleton_test_3month_hotpepper.pkl')\n",
    "\n",
    "pseudo_time_series_test6 = pd.read_pickle(data_folda+'skeleton_test_6month.pkl')\n",
    "pseudo_time_series_test6= reduce_mem_usage(pseudo_time_series_test6)\n",
    "pseudo_time_series_test6 = add_v_hotpepper(pseudo_time_series_test6, data_folda, add_list, master_name=\"V_HOTPEPPER\",read_from_snowflake=False) \n",
    "pseudo_time_series_test6.to_pickle(data_folda+'skeleton_test_6month_hotpepper.pkl')\n",
    "\n",
    "del pseudo_time_series, pseudo_time_series_test3, pseudo_time_series_test6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* V_STRUCTURED からデータを取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_list = '\"restaurant_id\",\"url\",\"name_rank\",\"address_rank\",\"telephone_rank\",\"aggregateRating.ratingCount\", \\\n",
    "    \"aggregateRating.ratingValue\", \"aggregateRating.reviewCount\", \\\n",
    "    \"aggregateRating.bestRating\", \"aggregateRating.worstRating\", \"interactionCount.went\", \\\n",
    "    \"interactionCount.wanttogo\",\"paymentAccepted\"'\n",
    "\n",
    "\n",
    "pseudo_time_series = pd.read_pickle(data_folda+'skeleton_train.pkl')\n",
    "pseudo_time_series=pseudo_time_series[pseudo_time_series['base_date']>='2022-12-31']\n",
    "pseudo_time_series = add_v_structured(pseudo_time_series, data_folda, add_list, master_name=\"V_STRUCTURED\",read_from_snowflake=True)\n",
    "pseudo_time_series.to_pickle(data_folda+'train_with_structured.pkl')\n",
    "\n",
    "del pseudo_time_series\n",
    "\n",
    "pseudo_time_series_test3 = pd.read_pickle(data_folda+'skeleton_test_3month.pkl')\n",
    "pseudo_time_series_test3 = add_v_structured(pseudo_time_series_test3, data_folda, add_list, master_name=\"V_STRUCTURED\",read_from_snowflake=True) \n",
    "pseudo_time_series_test3.to_pickle(data_folda+'skeleton_test_3month_structured.pkl')\n",
    "\n",
    "pseudo_time_series_test6 = pd.read_pickle(data_folda+'skeleton_test_6month.pkl')\n",
    "pseudo_time_series_test6 = add_v_structured(pseudo_time_series_test6, data_folda, add_list, master_name=\"V_STRUCTURED\",read_from_snowflake=True) \n",
    "pseudo_time_series_test6.to_pickle(data_folda+'skeleton_test_6month_structured.pkl')\n",
    "\n",
    "del pseudo_time_series_test3, pseudo_time_series_test6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* V_TRIPADVISOR から特徴量を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_v_tripadvisor(pseudo_time_series, data_folda, add_list, master_name=\"V_TRIPADVISOR\",read_from_snowflake=False):\n",
    "    pd_sf = read_table(data_folda,master_name,columns=\"all\",read_snowflake=read_from_snowflake,col=\"*\")\n",
    "\n",
    "    # general rank を与える\n",
    "    ranker=rank.Ranker()\n",
    "    pd_sf=ranker.add_general_rank(pd_sf)\n",
    "    pd_sf=select_general_rank(pd_sf)\n",
    "    pd_sf.rename(columns={\"general_rank\":\"general_rank_TRIPADVISOR\"},inplace=True)\n",
    "\n",
    "    pd_sf.rename(columns={\"infos.aggregateRating\":\"infos.aggregateRating_TRIPADVISOR\"},inplace=True)\n",
    "    #add_list=[\"restaurant_id\",\"infos.aggregateRating_TRIPADVISOR\",\"infos.ratingDetails.Meal\",\"infos.ratingDetails.Service\",\"infos.ratingDetails.Price\",\"infos.ratingDetails.Ambience\",\"infos.reviewCount\",\"infos.qa_count\"]\n",
    "\n",
    "\n",
    "    pd_sf_drop_dum=pd_sf[add_list]\n",
    "\n",
    "    # oficial_info_flg を categorical に変換\n",
    "    #pd_sf_drop_dum[\"infos.official_info_flg\"]=pd_sf_drop_dum[\"infos.official_info_flg\"].astype(\"category\")\n",
    "    pseudo_time_series=pseudo_time_series[[\"base_date\",\"restaurant_id\"]]\n",
    "    temp=pd.merge(pseudo_time_series,pd_sf_drop_dum,on=\"restaurant_id\",how=\"left\")\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/dglab-ai-scoring_insitestream/pg/./utils/rank.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"n_rank_count\"] = df[\"telephone_rank\"].isin([\"N\"]).astype(int) + df[\"address_rank\"].isin([\"N\"]).astype(int) + df[\"name_rank\"].isin([\"N\"]).astype(int)\n",
      "/home/ec2-user/dglab-ai-scoring_insitestream/pg/./utils/rank.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"denominator\"] = np.select(condition, choice, default=-1)\n",
      "/home/ec2-user/dglab-ai-scoring_insitestream/pg/./utils/rank.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"tel_numerator\"] = np.select(condition_tel, choice_tel, default=0) # rank N = 0\n",
      "/home/ec2-user/dglab-ai-scoring_insitestream/pg/./utils/rank.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"add_numerator\"] = np.select(condition_add, choice_add, default=0) # rank N = 0\n",
      "/home/ec2-user/dglab-ai-scoring_insitestream/pg/./utils/rank.py:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"name_numerator\"] = np.select(condition_name, choice_name, default=0) # rank N = 0\n",
      "/home/ec2-user/dglab-ai-scoring_insitestream/pg/./utils/rank.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"general_numerator\"] = df[\"tel_numerator\"] + df[\"add_numerator\"] + df[\"name_numerator\"]\n",
      "/home/ec2-user/dglab-ai-scoring_insitestream/pg/./utils/rank.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"division_result_value\"] = df[\"general_numerator\"] / df[\"denominator\"]\n",
      "/home/ec2-user/dglab-ai-scoring_insitestream/pg/./utils/rank.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"s_a_b_rank\"] = np.select(condition_result, choice_result, default=\"?\")\n",
      "/home/ec2-user/dglab-ai-scoring_insitestream/pg/./utils/rank.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"n_rank_count\"] = df[\"telephone_rank\"].isin([\"N\"]).astype(int) + df[\"address_rank\"].isin([\"N\"]).astype(int) + df[\"name_rank\"].isin([\"N\"]).astype(int)\n",
      "/home/ec2-user/dglab-ai-scoring_insitestream/pg/./utils/rank.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"denominator\"] = np.select(condition, choice, default=-1)\n",
      "/home/ec2-user/dglab-ai-scoring_insitestream/pg/./utils/rank.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"tel_numerator\"] = np.select(condition_tel, choice_tel, default=0) # rank N = 0\n",
      "/home/ec2-user/dglab-ai-scoring_insitestream/pg/./utils/rank.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"add_numerator\"] = np.select(condition_add, choice_add, default=0) # rank N = 0\n",
      "/home/ec2-user/dglab-ai-scoring_insitestream/pg/./utils/rank.py:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"name_numerator\"] = np.select(condition_name, choice_name, default=0) # rank N = 0\n",
      "/home/ec2-user/dglab-ai-scoring_insitestream/pg/./utils/rank.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"general_numerator\"] = df[\"tel_numerator\"] + df[\"add_numerator\"] + df[\"name_numerator\"]\n",
      "/home/ec2-user/dglab-ai-scoring_insitestream/pg/./utils/rank.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"division_result_value\"] = df[\"general_numerator\"] / df[\"denominator\"]\n",
      "/home/ec2-user/dglab-ai-scoring_insitestream/pg/./utils/rank.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"s_a_b_rank\"] = np.select(condition_result, choice_result, default=\"?\")\n",
      "/home/ec2-user/dglab-ai-scoring_insitestream/pg/./utils/rank.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"n_rank_count\"] = df[\"telephone_rank\"].isin([\"N\"]).astype(int) + df[\"address_rank\"].isin([\"N\"]).astype(int) + df[\"name_rank\"].isin([\"N\"]).astype(int)\n",
      "/home/ec2-user/dglab-ai-scoring_insitestream/pg/./utils/rank.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"denominator\"] = np.select(condition, choice, default=-1)\n",
      "/home/ec2-user/dglab-ai-scoring_insitestream/pg/./utils/rank.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"tel_numerator\"] = np.select(condition_tel, choice_tel, default=0) # rank N = 0\n",
      "/home/ec2-user/dglab-ai-scoring_insitestream/pg/./utils/rank.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"add_numerator\"] = np.select(condition_add, choice_add, default=0) # rank N = 0\n",
      "/home/ec2-user/dglab-ai-scoring_insitestream/pg/./utils/rank.py:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"name_numerator\"] = np.select(condition_name, choice_name, default=0) # rank N = 0\n",
      "/home/ec2-user/dglab-ai-scoring_insitestream/pg/./utils/rank.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"general_numerator\"] = df[\"tel_numerator\"] + df[\"add_numerator\"] + df[\"name_numerator\"]\n",
      "/home/ec2-user/dglab-ai-scoring_insitestream/pg/./utils/rank.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"division_result_value\"] = df[\"general_numerator\"] / df[\"denominator\"]\n",
      "/home/ec2-user/dglab-ai-scoring_insitestream/pg/./utils/rank.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"s_a_b_rank\"] = np.select(condition_result, choice_result, default=\"?\")\n"
     ]
    }
   ],
   "source": [
    "add_list=[\"restaurant_id\",\"general_rank_TRIPADVISOR\",'infos.aggregateRating_TRIPADVISOR',\"infos.reviewCount\",\"infos.qa_count\"]\n",
    "\n",
    "pseudo_time_series = pd.read_pickle(data_folda+'skeleton_train.pkl')\n",
    "pseudo_time_series=pseudo_time_series[pseudo_time_series['base_date']>='2022-12-31']\n",
    "pseudo_time_series = reduce_mem_usage(pseudo_time_series)\n",
    "pseudo_time_series = add_v_tripadvisor(pseudo_time_series, data_folda, add_list, master_name=\"V_TRIPADVISOR\",read_from_snowflake=False)\n",
    "pseudo_time_series.to_pickle(data_folda+'train_with_tripadvisor.pkl')\n",
    "\n",
    "del pseudo_time_series\n",
    "\n",
    "pseudo_time_series_test = pd.read_pickle(data_folda+'skeleton_test_3month.pkl')\n",
    "pseudo_time_series_test = reduce_mem_usage(pseudo_time_series_test)\n",
    "pseudo_time_series_test = add_v_tripadvisor(pseudo_time_series_test, data_folda, add_list, master_name=\"V_TRIPADVISOR\",read_from_snowflake=False) \n",
    "pseudo_time_series_test.to_pickle(data_folda+'skeleton_test_3month_tripadvisor.pkl')\n",
    "\n",
    "pseudo_time_series_test = pd.read_pickle(data_folda+'skeleton_test_6month.pkl')\n",
    "pseudo_time_series_test = reduce_mem_usage(pseudo_time_series_test)\n",
    "pseudo_time_series_test = add_v_tripadvisor(pseudo_time_series_test, data_folda, add_list, master_name=\"V_TRIPADVISOR\",read_from_snowflake=False) \n",
    "pseudo_time_series_test.to_pickle(data_folda+'skeleton_test_6month_tripadvisor.pkl')\n",
    "\n",
    "del pseudo_time_series_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* V_HITOSARA から特徴量を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hitosara premium を追加\n",
    "add_list=[\"restaurant_id\",\"infos.premium\",\"general_rank_HITOSARA\",\"infos.onlineReservation_HITOSARA\"]\n",
    "\n",
    "pseudo_time_series = pd.read_pickle(data_folda+'skeleton_train.pkl')\n",
    "pseudo_time_series=pseudo_time_series[pseudo_time_series['base_date']>='2022-12-31']\n",
    "pseudo_time_series= reduce_mem_usage(pseudo_time_series)\n",
    "pseudo_time_series = add_v_hitosara(pseudo_time_series, data_folda, add_list, master_name=\"V_HITOSARA\",read_from_snowflake=False)\n",
    "pseudo_time_series.to_pickle(data_folda+'train_with_hitosara.pkl')\n",
    "\n",
    "del pseudo_time_series\n",
    "\n",
    "pseudo_time_series_test = pd.read_pickle(data_folda+'skeleton_test_3month.pkl')\n",
    "pseudo_time_series_test= reduce_mem_usage(pseudo_time_series_test)\n",
    "pseudo_time_series_test = add_v_hitosara(pseudo_time_series_test, data_folda, add_list, master_name=\"V_HITOSARA\",read_from_snowflake=False) \n",
    "pseudo_time_series_test.to_pickle(data_folda+'skeleton_test_3month_hitosara.pkl')\n",
    "\n",
    "pseudo_time_series_test = pd.read_pickle(data_folda+'skeleton_test_6month.pkl')\n",
    "pseudo_time_series_test= reduce_mem_usage(pseudo_time_series_test)\n",
    "pseudo_time_series_test = add_v_hitosara(pseudo_time_series_test, data_folda, add_list, master_name=\"V_HITOSARA\",read_from_snowflake=False) \n",
    "pseudo_time_series_test.to_pickle(data_folda+'skeleton_test_6month_hitosara.pkl')\n",
    "\n",
    "del pseudo_time_series_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* v_review_google を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_series = pd.read_pickle(data_folda+'skeleton_train.pkl')\n",
    "pseudo_time_series=pseudo_time_series[pseudo_time_series['base_date']>='2022-12-31']\n",
    "\n",
    "# レビューの数\n",
    "pd_sf=pd.read_csv(data_folda+'feature_aggregation.csv')\n",
    "# クロール時のこれまでの全レビューのスコアの平均\n",
    "pd_sf2=pd.read_csv(data_folda+'restaurant_id_sentiment_score.csv')\n",
    "\n",
    "pd_sf=pd_sf[pd_sf['BASE_DATE']>='2022-12-31']\n",
    "pd_sf.rename(columns={\"BASE_DATE\":\"base_date\",\"RESTAURANT_ID\":\"restaurant_id\"},inplace=True)\n",
    "pseudo_time_series=pseudo_time_series[[\"base_date\",\"restaurant_id\"]]\n",
    "pd_sf[\"base_date\"]=pd.to_datetime(pd_sf[\"base_date\"]).dt.tz_localize(None)\n",
    "temp=pd.merge(pseudo_time_series,pd_sf,on=[\"base_date\",\"restaurant_id\"],how=\"left\")\n",
    "temp=pd.merge(temp,pd_sf2,on=[\"restaurant_id\"],how=\"left\")\n",
    "temp.to_pickle(data_folda+'train_with_feature_aggregation.pkl')\n",
    "\n",
    "pseudo_time_series = pd.read_pickle(data_folda+'skeleton_test_3month.pkl')\n",
    "pseudo_time_series=pseudo_time_series[[\"base_date\",\"restaurant_id\"]]\n",
    "temp=pd.merge(pseudo_time_series,pd_sf,on=[\"base_date\",\"restaurant_id\"],how=\"left\")\n",
    "temp=pd.merge(temp,pd_sf2,on=[\"restaurant_id\"],how=\"left\")\n",
    "temp.to_pickle(data_folda+'skeleton_test_3month_feature_aggregation.pkl')\n",
    "\n",
    "pseudo_time_series = pd.read_pickle(data_folda+'skeleton_test_6month.pkl')\n",
    "pseudo_time_series=pseudo_time_series[[\"base_date\",\"restaurant_id\"]]\n",
    "temp=pd.merge(pseudo_time_series,pd_sf,on=[\"base_date\",\"restaurant_id\"],how=\"left\")\n",
    "temp=pd.merge(temp,pd_sf2,on=[\"restaurant_id\"],how=\"left\")\n",
    "temp.to_pickle(data_folda+'skeleton_test_6month_feature_aggregation.pkl')\n",
    "\n",
    "del temp, pseudo_time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 近くの店の閉店率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/close_ratio_near_restaurant20230331.pkl\n",
      "(875314, 3)\n",
      "../data/close_ratio_near_restaurant20230630.pkl\n",
      "(1750628, 3)\n",
      "../data/close_ratio_near_restaurant20230930.pkl\n",
      "(2625942, 3)\n",
      "../data/close_ratio_near_restaurant20230430.pkl\n",
      "(3501256, 3)\n",
      "../data/close_ratio_near_restaurant20230731.pkl\n",
      "(4376570, 3)\n",
      "../data/close_ratio_near_restaurant20230531.pkl\n",
      "(5251884, 3)\n",
      "../data/close_ratio_near_restaurant20230831.pkl\n",
      "(6127198, 3)\n",
      "../data/close_ratio_near_restaurant20231031.pkl\n",
      "(7002512, 3)\n",
      "../data/close_ratio_near_restaurant20231130.pkl\n",
      "(7877826, 3)\n"
     ]
    }
   ],
   "source": [
    "add_list=['restaurant_id', 'base_date', 'close_ratio_near_restaurant_three_months']\n",
    "# folda + close_ratio_near_restaurant202*.pkl を全部読み込んで結合\n",
    "close_ratios=get_close_ratio(data_folda)\n",
    "\n",
    "pseudo_time_series = pd.read_pickle(data_folda+'skeleton_train.pkl')\n",
    "pseudo_time_series=pseudo_time_series[pseudo_time_series['base_date']>='2022-12-31']\n",
    "\n",
    "pseudo_time_series = pd.merge(pseudo_time_series,close_ratios,on=[\"restaurant_id\",\"base_date\"],how=\"left\")\n",
    "pseudo_time_series[add_list].to_pickle(data_folda+'skeleton_train_with_near_close_ratio.pkl')\n",
    "\n",
    "pseudo_time_series_test = pd.read_pickle(data_folda+'skeleton_test_3month.pkl')\n",
    "pseudo_time_series_test = pd.merge(pseudo_time_series_test,close_ratios,on=[\"restaurant_id\",\"base_date\"],how=\"left\")\n",
    "pseudo_time_series_test[add_list].to_pickle(data_folda+'skeleton_test_3month_near_close_ratio.pkl')\n",
    "\n",
    "pseudo_time_series_test = pd.read_pickle(data_folda+'skeleton_test_6month.pkl')\n",
    "pseudo_time_series_test = pd.merge(pseudo_time_series_test,close_ratios,on=[\"restaurant_id\",\"base_date\"],how=\"left\")\n",
    "pseudo_time_series_test[add_list].to_pickle(data_folda+'skeleton_test_6month_near_close_ratio.pkl')\n",
    "\n",
    "del pseudo_time_series, pseudo_time_series_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 近くの駅の数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist_from_station.ipynb で計算した最寄り駅データを読み込んで、concatenate する。\n",
    "pseudo_time_series = pd.read_pickle(data_folda+'skeleton_train.pkl')\n",
    "pseudo_time_series=pseudo_time_series[pseudo_time_series['base_date']>='2022-12-31']\n",
    "pseudo_time_series = pseudo_time_series[[\"base_date\",\"restaurant_id\"]]\n",
    "#cat_dummy=pd.read_pickle(data_folda+'category_dummies.pkl').drop([\"base_date\"],axis=1)\n",
    "# restaurant_id 以外は、カテゴリカル変数のカラムに _cat_dummy を付与\n",
    "#cat_dummy.columns = [col+\"_cat_dummy\" if col!=\"restaurant_id\" else col for col in cat_dummy.columns]\n",
    "\n",
    "staton=pd.read_csv(data_folda+\"/station_address/station20240318free.csv\")\n",
    "station_cd_count=staton.groupby('station_g_cd').size().reset_index(name='count').sort_values('count', ascending=False)\n",
    "# 同じ station_cd の数をカウントして、付与する\n",
    "station=pd.merge(staton,station_cd_count,on='station_g_cd',how='left')\n",
    "\n",
    "# near_station の駅id(station_cd) と距離（dist_from_station）に オリジナルファイル（station） から 乗り換え可能駅数（count） を付与\n",
    "near_station = pd.read_pickle(data_folda+'train_with_station_dist.pkl')\n",
    "near_station = near_station[[\"restaurant_id\",\"station_cd\",\"dist_from_station\"]]\n",
    "near_station=pd.merge(near_station,station[[\"station_cd\",\"count\"]], on='station_cd', how='left')[[\"restaurant_id\",\"dist_from_station\",\"count\"]]\n",
    "\n",
    "# トレーニングデータに最寄り駅情報を付与\n",
    "pseudo_time_series = pd.merge(pseudo_time_series,near_station,on=\"restaurant_id\",how=\"left\")\n",
    "#pseudo_time_series = pd.merge(pseudo_time_series,cat_dummy,on=\"restaurant_id\",how=\"left\")\n",
    "pseudo_time_series.to_pickle(data_folda+'skeleton_train_near_station.pkl')\n",
    "\n",
    "# 3ヵ月予測テストデータに最寄り駅情報を付与\n",
    "pseudo_time_series = pd.read_pickle(data_folda+'skeleton_test_3month.pkl')\n",
    "pseudo_time_series = pseudo_time_series[[\"base_date\",\"restaurant_id\"]]\n",
    "pseudo_time_series = pd.merge(pseudo_time_series,near_station,on=\"restaurant_id\",how=\"left\")\n",
    "pseudo_time_series.to_pickle(data_folda+'skeleton_test_3month_near_station.pkl')\n",
    "\n",
    "# 6ヵ月予測テストデータに最寄り駅情報を付与\n",
    "pseudo_time_series = pd.read_pickle(data_folda+'skeleton_test_6month.pkl')\n",
    "pseudo_time_series = pseudo_time_series[[\"base_date\",\"restaurant_id\"]]\n",
    "pseudo_time_series = pd.merge(pseudo_time_series,near_station,on=\"restaurant_id\",how=\"left\")\n",
    "pseudo_time_series.to_pickle(data_folda+'skeleton_test_6month_near_station.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_with_master.pkl\n",
      "train_with_hotpepper.pkl\n",
      "train_with_google.pkl\n",
      "train_with_retty.pkl\n",
      "train_with_tripadvisor.pkl\n",
      "train_with_hitosara.pkl\n",
      "train_with_feature_aggregation.pkl\n",
      "skeleton_train_near_station.pkl\n",
      "skeleton_train_with_near_close_ratio.pkl\n"
     ]
    }
   ],
   "source": [
    "#train_with_hotpepper.pkl      \n",
    "#train_with_google.pkl  \n",
    "#train_with_master.pkl         \n",
    "#train_with_retty.pkl          \n",
    "#train_with_tripadvisor.pkl\n",
    "# 上記五つを pd.concatで結合。 train_with_master 以外は、base_date と restaurant_id が重複するため、あらかじめ削除しておく\n",
    "\n",
    "concat_list=[\"train_with_master.pkl\",\"train_with_hotpepper.pkl\",\"train_with_google.pkl\",\"train_with_retty.pkl\",\"train_with_tripadvisor.pkl\"\n",
    "             ,\"train_with_hitosara.pkl\",\"train_with_feature_aggregation.pkl\",\"skeleton_train_near_station.pkl\",\"skeleton_train_with_near_close_ratio.pkl\"]\n",
    "#pseudo_time_series=pseudo_time_series.drop([\"base_date\",\"restaurant_id\"],axis=1)\n",
    "df=pd.DataFrame()\n",
    "for i, fn in enumerate(concat_list):\n",
    "    print(fn)\n",
    "        \n",
    "    df_=pd.read_pickle(data_folda+fn)\n",
    "    if(i==0):\n",
    "        pass\n",
    "    else:\n",
    "        df_=df_.drop([\"base_date\",\"restaurant_id\"],axis=1)\n",
    "    \n",
    "    df=pd.concat([df,df_],axis=1)\n",
    "    del df_\n",
    "    \n",
    "df.to_pickle(data_folda+'train_with_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skeleton_test_3month_master.pkl\n",
      "skeleton_test_3month_hotpepper.pkl\n",
      "skeleton_test_3month_google.pkl\n",
      "skeleton_test_3month_retty.pkl\n",
      "skeleton_test_3month_tripadvisor.pkl\n",
      "skeleton_test_3month_hitosara.pkl\n",
      "skeleton_test_3month_feature_aggregation.pkl\n",
      "skeleton_test_3month_near_station.pkl\n",
      "skeleton_test_3month_near_close_ratio.pkl\n"
     ]
    }
   ],
   "source": [
    "concat_list=[\"skeleton_test_3month_master.pkl\",\"skeleton_test_3month_hotpepper.pkl\",\"skeleton_test_3month_google.pkl\",\"skeleton_test_3month_retty.pkl\",\"skeleton_test_3month_tripadvisor.pkl\"\n",
    "             ,\"skeleton_test_3month_hitosara.pkl\",\"skeleton_test_3month_feature_aggregation.pkl\",\"skeleton_test_3month_near_station.pkl\",\"skeleton_test_3month_near_close_ratio.pkl\"]\n",
    "#pseudo_time_series=pseudo_time_series.drop([\"base_date\",\"restaurant_id\"],axis=1)\n",
    "df=pd.DataFrame()\n",
    "for i, fn in enumerate(concat_list):\n",
    "    print(fn)\n",
    "        \n",
    "    df_=pd.read_pickle(data_folda+fn)\n",
    "    if(i==0):\n",
    "        pass\n",
    "    else:\n",
    "        df_=df_.drop([\"base_date\",\"restaurant_id\"],axis=1)\n",
    "    \n",
    "    df=pd.concat([df,df_],axis=1)\n",
    "df.to_pickle(data_folda+'test3_with_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skeleton_test_6month_master.pkl\n",
      "skeleton_test_6month_hotpepper.pkl\n",
      "skeleton_test_6month_google.pkl\n",
      "skeleton_test_6month_retty.pkl\n",
      "skeleton_test_6month_tripadvisor.pkl\n",
      "skeleton_test_6month_hitosara.pkl\n",
      "skeleton_test_6month_feature_aggregation.pkl\n",
      "skeleton_test_6month_near_station.pkl\n",
      "skeleton_test_6month_near_close_ratio.pkl\n"
     ]
    }
   ],
   "source": [
    "concat_list=[\"skeleton_test_6month_master.pkl\",\"skeleton_test_6month_hotpepper.pkl\",\"skeleton_test_6month_google.pkl\",\"skeleton_test_6month_retty.pkl\",\"skeleton_test_6month_tripadvisor.pkl\"\n",
    "             ,\"skeleton_test_6month_hitosara.pkl\",\"skeleton_test_6month_feature_aggregation.pkl\",\"skeleton_test_6month_near_station.pkl\",\"skeleton_test_6month_near_close_ratio.pkl\"]\n",
    "#pseudo_time_series=pseudo_time_series.drop([\"base_date\",\"restaurant_id\"],axis=1)\n",
    "df=pd.DataFrame()\n",
    "for i, fn in enumerate(concat_list):\n",
    "    print(fn)\n",
    "        \n",
    "    df_=pd.read_pickle(data_folda+fn)\n",
    "    if(i==0):\n",
    "        pass\n",
    "    else:\n",
    "        df_=df_.drop([\"base_date\",\"restaurant_id\"],axis=1)\n",
    "    \n",
    "    df=pd.concat([df,df_],axis=1)\n",
    "df.to_pickle(data_folda+'test6_with_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudo_time_series_filter[general_rank_columns]をプロット\n",
    "# 横軸を S,A,B,L,F,N,NaNの分布\n",
    "# 一つのキャンバスにプロット\n",
    "general_rank_columns=[\"general_rank_HOTPEPPER\",\"general_rank_GOOGLE\",\"general_rank_HITOSARA\",\"general_rank_RETTY\",\"general_rank_TRIPADVISOR\"]\n",
    "pseudo_time_series_filter=pseudo_time_series[general_rank_columns]\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for column in general_rank_columns:\n",
    "    print(column,pseudo_time_series_filter[column].unique())\n",
    "    # 前のプロットを上書きする\n",
    "    ax.hist(pseudo_time_series_filter[column])\n",
    "\n",
    "plt.show()\n",
    "\"\"\"\n",
    "for column in general_rank_columns:\n",
    "    print(column,pseudo_time_series_filter[column].unique())\n",
    "    # 前のプロットを上書きする\n",
    "    pseudo_time_series_filter[column].value_counts().plot(kind='bar',title=column,ax=plt.gca())\n",
    "    plt.show()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton_train[\"general_rank_HITOSARA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton_train=pd.read_pickle(data_folda+'skeleton_train.pkl')\n",
    "skeleton_train=pd.merge(skeleton_train,pseudo_time_series_filter[[\"restaurant_id\"]+general_rank_columns],on=\"restaurant_id\",how=\"left\")\n",
    "skeleton_train.to_pickle(data_folda+'skeleton_train_with_general_rank.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton_test=pd.read_pickle(data_folda+'skeleton_test.pkl')\n",
    "skeleton_test=pd.merge(skeleton_test,pseudo_time_series_filter[[\"restaurant_id\"]+general_rank_columns],on=\"restaurant_id\",how=\"left\")\n",
    "skeleton_test.to_pickle(data_folda+'skeleton_test_with_general_rank.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_series_filter[pseudo_time_series_filter[\"general_rank_HITOSARA\"].isin([\"A\",\"B\",\"S\",\"L\",\"N\",\"F\"])][\"general_rank_HITOSARA\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_filter=pseudo_time_series_filter[pseudo_time_series_filter[\"general_rank_GOOGLE\"].isin([\"A\",\"B\",\"S\",\"L\",\"N\",\"F\"])]\n",
    "g_filter_=g_filter[g_filter[\"general_rank_RETTY\"].isin([\"A\",\"B\",\"S\",\"L\",\"N\",\"F\"])]\n",
    "g_filter_=g_filter_[g_filter_[\"general_rank_HOTPEPPER\"].isin([\"A\",\"B\",\"S\",\"L\",\"N\",\"F\"])]\n",
    "g_filter_=g_filter_[g_filter_[\"general_rank_HITOSARA\"].isin([\"A\",\"B\",\"S\",\"L\",\"N\",\"F\"])]\n",
    "g_filter_=g_filter_[g_filter_[\"general_rank_TRIPADVISOR\"].isin([\"A\",\"B\",\"S\",\"L\",\"N\",\"F\"])]\n",
    "g_filter_=g_filter_[g_filter_[\"general_rank_STRUCTURED\"].isin([\"A\",\"B\",\"S\",\"L\",\"N\",\"F\"])]\n",
    "\n",
    "print(g_filter.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_series_filter[pseudo_time_series_filter[\"general_rank_GOOGLE\"].isin([\"A\",\"B\",\"S\",\"L\",\"N\",\"F\"])][\"general_rank_HITOSARA\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggoogle=pseudo_time_series_filter[pseudo_time_series_filter[\"general_rank_GOOGLE\"].isin([\"A\",\"B\",\"S\",\"L\",\"N\",\"F\"])][\"general_rank_GOOGLE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_num=pd.DataFrame()\n",
    "for column in general_rank_columns:\n",
    "    print(column,pseudo_time_series_filter[column].dropna().shape[0])\n",
    "    #上記を転置してrank_numに追加\n",
    "    rank_num=rank_num.append([[column,pseudo_time_series_filter[column].dropna().shape[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_num.sort_values(by=1,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_num=pd.DataFrame()\n",
    "for column in general_rank_columns:\n",
    "    num=pseudo_time_series_filter[pseudo_time_series_filter[\"closed_date\"].isna()==False][column].dropna().shape[0]\n",
    "    ratio=num/len(pseudo_time_series_filter[pseudo_time_series_filter[\"closed_date\"].isna()==False])\n",
    "    print(column,num,ratio)\n",
    "    #上記を転置してrank_numに追加\n",
    "    rank_num=rank_num.append([[column,num,ratio]])\n",
    "rank_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_num=pd.DataFrame()\n",
    "for column in general_rank_columns:\n",
    "    num=pseudo_time_series_filter[column].dropna().shape[0]\n",
    "    ratio=num/len(pseudo_time_series_filter)\n",
    "    print(column,num,ratio)\n",
    "    #上記を転置してrank_numに追加\n",
    "    rank_num=rank_num.append([[column,num,ratio]])\n",
    "rank_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_series_filter[\"closed_date\"].dropna().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_num.sort_values(by=1,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_filter=pseudo_time_series_filter\n",
    "rlist=[\"A\",\"B\",\"S\",\"L\",\"N\",\"F\"]\n",
    "rlist=[\"A\",\"B\",\"S\"]\n",
    "#num_restaurants=pd.DataFrame()\n",
    "for column in rank_num.sort_values(by=1,ascending=False)[0].values:\n",
    "    if(column==\"general_rank_STRUCTURED\"):\n",
    "        continue\n",
    "    g_filter=g_filter[g_filter[column].isin(rlist)]\n",
    "    num_restaurants=num_restaurants.append([[column,g_filter[g_filter[column].isin(rlist)][column].shape[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general_rank_GOOGLE, general_rank_RETTY, general_rank_HOTPEPPER, general_rank_HITOSARA, general_rank_TRIPADVISORそれぞれがある無しで、どの程度のレストランが抽出されるかを確認\n",
    "\n",
    "# 各メディアの true False を保存する dataframe を作成\n",
    "num_restaurants=pd.DataFrame()\n",
    "\n",
    "#rlist=[\"A\",\"B\",\"S\",\"L\",\"N\",\"F\"]\n",
    "rlist=[\"A\",\"B\",\"S\"]\n",
    "\n",
    "for is_google in [True,False]:\n",
    "    for is_retty in [True,False]:\n",
    "        for is_hotpepper in [True,False]:\n",
    "            for is_hitosara in [True,False]:\n",
    "                for is_tripadvisor in [True,False]:\n",
    "                    g_filter=pseudo_time_series_filter\n",
    "                    if is_google:\n",
    "                        g_filter=g_filter[g_filter[\"general_rank_GOOGLE\"].isin(rlist)]\n",
    "                    if is_retty:\n",
    "                        g_filter=g_filter[g_filter[\"general_rank_RETTY\"].isin(rlist)]\n",
    "                    if is_hotpepper:\n",
    "                        g_filter=g_filter[g_filter[\"general_rank_HOTPEPPER\"].isin(rlist)]\n",
    "                    if is_hitosara:\n",
    "                        g_filter=g_filter[g_filter[\"general_rank_HITOSARA\"].isin(rlist)]\n",
    "                    if is_tripadvisor:\n",
    "                        g_filter=g_filter[g_filter[\"general_rank_TRIPADVISOR\"].isin(rlist)]\n",
    "                    print(is_google,is_retty,is_hotpepper,is_hitosara,is_tripadvisor,g_filter.shape[0])\n",
    "                    \n",
    "                    num_restaurants=num_restaurants.append([[is_google,is_retty,is_hotpepper,is_hitosara,is_tripadvisor,g_filter.shape[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_restaurants　の is_google, is_retty, is_hotpepper, is_hitosara, is_tripadvisor を0,1,2,3,4から代入\n",
    "num_restaurants.columns=[\"is_google\",\"is_retty\",\"is_hotpepper\",\"is_hitosara\",\"is_tripadvisor\",\"num_restaurants\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_restaurants=num_restaurants.drop([0,1,2,3,4,5],axis=1)\n",
    "num_restaurants[\"num_restaurants\"]=num_restaurants[\"num_restaurants\"].astype(int)\n",
    "num_restaurants.sort_values(by=\"num_restaurants\",ascending=False,inplace=True)\n",
    "num_restaurants[[\"is_google\",\"is_retty\",\"is_hotpepper\",\"is_hitosara\",\"is_tripadvisor\",\"num_restaurants\"]]\n",
    "num_restaurants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scoring",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
